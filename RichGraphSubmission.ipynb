{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230f4afa-2b46-4834-95e7-e17c23d9b897",
   "metadata": {},
   "source": [
    "Load tf-idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a88fcba-3326-441d-9cd5-7664badaca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "sparsevectors={}\n",
    "with open('text_vectors.pkl', 'rb') as f:\n",
    "    sparsevectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfb3a7-3d6c-4634-b1db-ce4eb645810e",
   "metadata": {},
   "source": [
    "Load train and our edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370e93d3-4bfe-46f7-9b13-507dd19a1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_edges=pd.read_csv('train.csv')\n",
    "df_edges_all = df_edges[['id1', 'id2']]\n",
    "\n",
    "# load edges from tzt file (new_edges.txt)\n",
    "dfouredges=pd.read_csv(\"new_edges.txt\",header=None,names=[\"id1\",\"id2\"])\n",
    "\n",
    "dfouredges[\"id1\"]=dfouredges[\"id1\"].astype(int)\n",
    "dfouredges[\"id2\"]=dfouredges[\"id2\"].astype(int)\n",
    "\n",
    "df_edges_all=pd.concat([df_edges_all, dfouredges], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c43ace-4708-45e3-8840-fdc8060cfaca",
   "metadata": {},
   "source": [
    "Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "901c4374-e818-48b8-a355-c1b9af95db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The existing graph\n",
    "import networkx as nx\n",
    "G= nx.Graph()\n",
    "#add nodes\n",
    "nodes = pd.unique(df_edges_all[['id1', 'id2']].values.ravel())\n",
    "G.add_nodes_from(nodes)\n",
    "#add edges\n",
    "edges = [(row.id1,row.id2) for row in df_edges[df_edges[\"label\"]==1].itertuples()]\n",
    "G.add_edges_from(edges)\n",
    "edges2 = [(row.id1,row.id2) for row in dfouredges.itertuples()]\n",
    "G.add_edges_from(edges2)\n",
    "\n",
    "\n",
    "# keeping all the negative edges so we can compare results\n",
    "no_edges = [(row.id1,row.id2) for row in df_edges[df_edges[\"label\"]==0].itertuples()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ba303-f4f3-4328-8227-0e58c7b80fcd",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d6427f5-e01b-42ea-bc59-d917194ae969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Adding methods proposed in the https://link.springer.com/content/pdf/10.1038/s41598-019-57304-y.pdf\n",
    "def shortest_path(G:nx.Graph,source:int,target:int)->float:\n",
    "    try:\n",
    "        p=nx.shortest_path(G,source=source,target=target)\n",
    "        return len(p)-1\n",
    "    except nx.NetworkXNoPath:\n",
    "        return float(\"inf\")\n",
    "\n",
    "def distance(G:nx.Graph,source:int,target:int)->float:\n",
    "   '''\n",
    "   This method can be changed to any distance\n",
    "   '''\n",
    "   return shortest_path(G,source,target)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def distance_description(G,source:int,target:int)->float:\n",
    "    '''\n",
    "    This method can be changed to any distance\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    sp1=sparsevectors[source]\n",
    "    sp2=sparsevectors[target]\n",
    "    \n",
    "    return cosine_similarity(sp1,sp2)[0][0]\n",
    "\n",
    "\n",
    "def closeness_centrality(G:nx.Graph, source:int, target:int)->float:\n",
    "    dxy = nx.shortest_path(G,source=source,target=target)\n",
    "    return G.number_of_nodes()/shortest_path(G,source,target)\n",
    "\n",
    "def common_neighbors(G:nx.Graph, source:int, target:int)->list:\n",
    "    s_neighbors = list(G.adj[source].keys())\n",
    "    t_neighbors = list(G.adj[target].keys())\n",
    "    common_neighbors = set(s_neighbors).intersection(t_neighbors)\n",
    "    return common_neighbors\n",
    "\n",
    "def CCPA(G:nx.Graph, source:int, target:int,a:float = 0.5)->float:\n",
    "    '''\n",
    "    Common Neighbor and Centrality based Parameterized Algorithm\n",
    "    '''\n",
    "    return a*closeness_centrality(G,source,target)+(1-a)*len(common_neighbors(G,source,target))\n",
    "\n",
    "def CND(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Common Neighbor and Distance\n",
    "    '''\n",
    "    cn = common_neighbors(G,source,target)\n",
    "    if len(cn)>0:\n",
    "        return (len(cn)+1)/2\n",
    "    else:\n",
    "        if distance(G,source,target)==0:\n",
    "            return 0\n",
    "        return 1/distance(G,source,target)\n",
    "\n",
    "def PA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Preferential Attachment\n",
    "    '''\n",
    "    return G.degree[source]*G.degree[target]\n",
    "\n",
    "def AA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Adamic Adar\n",
    "    '''\n",
    "    similarity = 0.0\n",
    "    for neighbor in common_neighbors(G,source,target):\n",
    "        degree = G.degree[neighbor]\n",
    "        if degree > 1:\n",
    "            similarity += 1 / math.log(degree)\n",
    "    return similarity\n",
    "\n",
    "def CN(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Common Neighbor\n",
    "    '''\n",
    "    return len(common_neighbors(G,source,target))\n",
    "\n",
    "def SI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Sorensen Index\n",
    "    '''\n",
    "    if (G.degree[source]+G.degree[target]) ==0:\n",
    "        return 0\n",
    "    return 2*CN(G,source,target)/(G.degree[source]+G.degree[target])\n",
    "\n",
    "def JI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Jaccard Index\n",
    "    '''\n",
    "    s_neighbors = list(G.adj[source].keys())\n",
    "    t_neighbors = list(G.adj[target].keys())\n",
    "    common_neighbors = set(s_neighbors).intersection(t_neighbors)\n",
    "    all_neighbors = set(s_neighbors).union(t_neighbors)\n",
    "    if len(all_neighbors)==0:\n",
    "        return 0\n",
    "    return len(common_neighbors)/len(all_neighbors)\n",
    "\n",
    "def RA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Resource Allocation\n",
    "    '''\n",
    "    similarity = 0.0\n",
    "    for neighbor in common_neighbors(G,source,target):\n",
    "        degree = G.degree[neighbor]\n",
    "        if degree > 1:\n",
    "            similarity += 1 / degree\n",
    "    return similarity\n",
    "\n",
    "def HPI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Hub Promoted Index\n",
    "    '''\n",
    "    if min([G.degree[source],G.degree[target]]) ==0 :\n",
    "        return 0\n",
    "    return CN(G,source,target)/min([G.degree[source],G.degree[target]])\n",
    "\n",
    "def create_metric_vector(tup):\n",
    "    G=tup[0]\n",
    "    source= tup[1]\n",
    "    target= tup[2]\n",
    "    functions = [CND, PA, AA, CN, SI, JI, RA, HPI,distance_description]\n",
    "    outputs = []\n",
    "    for func in functions:\n",
    "        output = func(G, source, target)\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a2d19-d2cf-419b-acdd-169b20639388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "297a1b59-b4df-484f-b8c7-ba59536167e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "def makedataset(df):\n",
    "    label=df.label\n",
    "    data=[]\n",
    "    allind=len(df.index)\n",
    "    counter=0\n",
    "    tups=[]\n",
    "    for i in tqdm(range(len(df.index))):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        tups.append((G,row.id1,row.id2))\n",
    "    with Pool(4) as p:\n",
    "        data=p.map(create_metric_vector, tups)\n",
    "    \n",
    "    datadf=pd.DataFrame(data)\n",
    "    return datadf,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4aa55e-5197-4605-900a-e2cff8ea8622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 948232/948232 [00:44<00:00, 21275.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "X,Y=makedataset(df_edges)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "#start = time.time()\n",
    "#X,Y=makedataset(df_edges)\n",
    "#end = time.time()\n",
    "#print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea97448-8c3e-4c56-9d97-d6ec29a00ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "model = XGBClassifier()\n",
    "\n",
    "X_train, X_test, y_trainn, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_trainn)\n",
    "preds = model.predict(X_test)\n",
    "f1=f1_score(y_test, preds)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda9d7f-d3c3-436c-8dc5-d457fe465c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
