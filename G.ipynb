{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866955ef-ba30-485c-b27a-900b4578773d",
   "metadata": {},
   "source": [
    " This method involves using the original graph, constructed from the provided edges. We generate a graph vector for each node pair by employing the metrics defined in paper. These vectors are used to train the classifier, which is then employed to predict the labels for new incoming edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac632f3d-b5c1-4d1f-b150-31977a1409ab",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ace6b9-0d49-4cb1-9150-6dd543b28a19",
   "metadata": {},
   "source": [
    "Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80aa5392-1aa3-4b21-8a78-326fed189204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train dataset\n",
    "import pandas as pd\n",
    "\n",
    "df_edges_all=pd.read_csv('train.csv')\n",
    "df_edges_all_test=pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "df_edges= df_edges_all\n",
    "\n",
    "import pickle \n",
    "sparsevectors={}\n",
    "with open('text_vectors.pkl', 'rb') as f:\n",
    "    sparsevectors = pickle.load(f)\n",
    "\n",
    "# The existing graph\n",
    "import networkx as nx\n",
    "\n",
    "G= nx.Graph()\n",
    "#add nodes\n",
    "nodestest=pd.unique(df_edges_all_test[['id1', 'id2']].values.ravel())\n",
    "nodes = pd.unique(df_edges_all[['id1', 'id2']].values.ravel())\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_nodes_from(nodestest)\n",
    "\n",
    "#add edges\n",
    "edges = [(row.id1,row.id2) for row in df_edges[df_edges[\"label\"]==1].itertuples()]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# keeping all the negative edges so we can compare results\n",
    "no_edges = [(row.id1,row.id2) for row in df_edges[df_edges[\"label\"]==0].itertuples()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e2f76-7c46-413d-8f4f-e80c44b894ed",
   "metadata": {},
   "source": [
    "Define graph metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca1b7ea-7576-41e3-9f49-c4187329a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Adding methods proposed in the https://link.springer.com/content/pdf/10.1038/s41598-019-57304-y.pdf\n",
    "def shortest_path(G:nx.Graph,source:int,target:int)->float:\n",
    "    try:\n",
    "        p=nx.shortest_path(G,source=source,target=target)\n",
    "        return len(p)-1\n",
    "    except nx.NetworkXNoPath:\n",
    "        return float(\"inf\")\n",
    "\n",
    "def distance(G:nx.Graph,source:int,target:int)->float:\n",
    "   '''\n",
    "   This method can be changed to any distance\n",
    "   '''\n",
    "   return shortest_path(G,source,target)\n",
    "\n",
    "def closeness_centrality(G:nx.Graph, source:int, target:int)->float:\n",
    "    dxy = nx.shortest_path(G,source=source,target=target)\n",
    "    return G.number_of_nodes()/shortest_path(G,source,target)\n",
    "\n",
    "def common_neighbors(G:nx.Graph, source:int, target:int)->list:\n",
    "    s_neighbors = list(G.adj[source].keys())\n",
    "    t_neighbors = list(G.adj[target].keys())\n",
    "    common_neighbors = set(s_neighbors).intersection(t_neighbors)\n",
    "    return common_neighbors\n",
    "\n",
    "def CCPA(G:nx.Graph, source:int, target:int,a:float = 0.5)->float:\n",
    "    '''\n",
    "    Common Neighbor and Centrality based Parameterized Algorithm\n",
    "    '''\n",
    "    return a*closeness_centrality(G,source,target)+(1-a)*len(common_neighbors(G,source,target))\n",
    "\n",
    "def CND(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Common Neighbor and Distance\n",
    "    '''\n",
    "    cn = common_neighbors(G,source,target)\n",
    "    if len(cn)>0:\n",
    "        return (len(cn)+1)/2\n",
    "    else:\n",
    "        if distance(G,source,target)==0:\n",
    "            return 0\n",
    "        return 1/distance(G,source,target)\n",
    "\n",
    "def PA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Preferential Attachment\n",
    "    '''\n",
    "    return G.degree[source]*G.degree[target]\n",
    "\n",
    "def AA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Adamic Adar\n",
    "    '''\n",
    "    similarity = 0.0\n",
    "    for neighbor in common_neighbors(G,source,target):\n",
    "        degree = G.degree[neighbor]\n",
    "        if degree > 1:\n",
    "            similarity += 1 / math.log(degree)\n",
    "    return similarity\n",
    "\n",
    "def CN(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Common Neighbor\n",
    "    '''\n",
    "    return len(common_neighbors(G,source,target))\n",
    "\n",
    "def SI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Sorensen Index\n",
    "    '''\n",
    "    if (G.degree[source]+G.degree[target]) ==0:\n",
    "        return 0\n",
    "    return 2*CN(G,source,target)/(G.degree[source]+G.degree[target])\n",
    "\n",
    "def JI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Jaccard Index\n",
    "    '''\n",
    "    s_neighbors = list(G.adj[source].keys())\n",
    "    t_neighbors = list(G.adj[target].keys())\n",
    "    common_neighbors = set(s_neighbors).intersection(t_neighbors)\n",
    "    all_neighbors = set(s_neighbors).union(t_neighbors)\n",
    "    if len(all_neighbors)==0:\n",
    "        return 0\n",
    "    return len(common_neighbors)/len(all_neighbors)\n",
    "\n",
    "def RA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Resource Allocation\n",
    "    '''\n",
    "    similarity = 0.0\n",
    "    for neighbor in common_neighbors(G,source,target):\n",
    "        degree = G.degree[neighbor]\n",
    "        if degree > 1:\n",
    "            similarity += 1 / degree\n",
    "    return similarity\n",
    "\n",
    "def HPI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Hub Promoted Index\n",
    "    '''\n",
    "    if min([G.degree[source],G.degree[target]]) ==0 :\n",
    "        return 0\n",
    "    return CN(G,source,target)/min([G.degree[source],G.degree[target]])\n",
    "\n",
    "def create_metric_vector(tup):\n",
    "    G=tup[0]\n",
    "    source= tup[1]\n",
    "    target= tup[2]\n",
    "    functions = [CND, PA, AA, CN, SI, JI, RA, HPI]\n",
    "    outputs = []\n",
    "    for func in functions:\n",
    "        output = func(G, source, target)\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def makedatasetapply(df):\n",
    "    label=df.label\n",
    "    datadf = df.apply(lambda row: create_metric_vector((G,row['id1'],row['id2'])), axis=1,result_type='expand')\n",
    "    return datadf,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d423bd-7961-4f36-9eb1-c2b3da3eb6d1",
   "metadata": {},
   "source": [
    "Create vector for each pair in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37791cbc-4064-49b6-bcf7-584747d1b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X,Y=makedatasetapply(df_edges)\n",
    "\n",
    "Xcopy=X.copy()\n",
    "Xcopy[\"label\"]=Y\n",
    "Xcopy.to_csv(\"simple_vectors_with_labels.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21488b1-e84c-4752-aede-6054212a887d",
   "metadata": {},
   "source": [
    "Train a classifier in vectors derived fromt training setfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0b97d7-5747-4ff4-961b-3012342142c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "Xcopy=pd.read_csv(\"simple_vectors_with_labels.csv\")\n",
    "Y=Xcopy[\"label\"]\n",
    "X=Xcopy.drop([\"label\"],axis=1)\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70417ae6-45ba-4aec-8000-e25980d1ec08",
   "metadata": {},
   "source": [
    "# Online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c36ab-1071-4d3f-994b-18c733e97b42",
   "metadata": {},
   "source": [
    "Create vectors using the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd490a99-aa3b-4b62-bd3c-6a4f401b880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedataset_TEST(df):\n",
    "    datadf = df.apply(lambda row: create_metric_vector((G,row['id1'],row['id2'])), axis=1,result_type='expand')\n",
    "    return datadf\n",
    "\n",
    "X_test=makedataset_TEST(df_edges_all_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8193e-a9ea-45cd-98f8-ca87532220a6",
   "metadata": {},
   "source": [
    "Produce predictions using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda5ebd1-bb51-4433-897a-4d9b734ba98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe3377-bc0c-448c-ba1e-29d910f3de04",
   "metadata": {},
   "source": [
    "Store predictions to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ead795-58c3-491a-8699-fc3f41df7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexpe=pd.DataFrame(zip(df_edges_all_test[\"id\"].values,preds),columns=[\"id\",\"label\"])\n",
    "dfexpe.to_csv(\"simple_graph_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3f7cb-cae0-4e90-97ad-016fd410fd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
