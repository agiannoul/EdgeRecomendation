{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9202</td>\n",
       "      <td>9202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>410411</td>\n",
       "      <td>460254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>211858</td>\n",
       "      <td>312074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>253901</td>\n",
       "      <td>504325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>415071</td>\n",
       "      <td>63239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     id1     id2  label\n",
       "0   1    9202    9202      1\n",
       "1   2  410411  460254      0\n",
       "2   3  211858  312074      1\n",
       "3   6  253901  504325      0\n",
       "4   7  415071   63239      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import train dataset\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('train.csv')\n",
    "\n",
    "df_edges_all=pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "df_edges= df_edges_all.iloc[:int(len(df_edges_all)*0.8)]\n",
    "\n",
    "df_edges_test = df_edges_all.iloc[int(len(df_edges_all)*0.8):]\n",
    "df_edges.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>758585</th>\n",
       "      <td>976717</td>\n",
       "      <td>345657</td>\n",
       "      <td>467621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758586</th>\n",
       "      <td>976719</td>\n",
       "      <td>825394</td>\n",
       "      <td>20456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758587</th>\n",
       "      <td>976720</td>\n",
       "      <td>720678</td>\n",
       "      <td>447520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758588</th>\n",
       "      <td>976721</td>\n",
       "      <td>181991</td>\n",
       "      <td>649051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758589</th>\n",
       "      <td>976723</td>\n",
       "      <td>663566</td>\n",
       "      <td>821902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     id1     id2  label\n",
       "758585  976717  345657  467621      1\n",
       "758586  976719  825394   20456      1\n",
       "758587  976720  720678  447520      0\n",
       "758588  976721  181991  649051      1\n",
       "758589  976723  663566  821902      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdesc= pd.read_csv('nodes/nodes.tsv', sep='\\t', header=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837834, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{{infobox person | name = clayton jacobson | i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a '''cobra probe''' is a device to measure the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the '''harmon foundation''' was established in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'''structured finance''' is a sector of financ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'''al-shohada'a stadium''' is a multi-use stad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "id                                                   \n",
       "1   {{infobox person | name = clayton jacobson | i...\n",
       "2   a '''cobra probe''' is a device to measure the...\n",
       "3   the '''harmon foundation''' was established in...\n",
       "4   '''structured finance''' is a sector of financ...\n",
       "5   '''al-shohada'a stadium''' is a multi-use stad..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfdesc.shape)\n",
    "dfdesc=dfdesc.set_index('id')\n",
    "dfdesc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{infobox person | name = clayton jacobson | image = | imagesize = | caption = | birth_name = | birth_date = | birth_place = | death_date = <!-- death date then birth --> | death_place = | other_names = | occupation = director, producer, writer, actor, editor | years_active = 1989 – present | spouse = | partner = | website = }} '''clayton jacobson''' (born 26 october 1963) is an australian film director, writer, producer, actor, musician and editor. his debut feature film was'' kenny (2006 film)''. ''kenny'' was released in 2006 in australia to critical acclaim, winning a number of awards. jacobson has also acted in a number of films, including 2010's ''animal kingdom (film)''. he is the brother of ''kenny'' actor shane jacobson. he also plays bass in the appalachian folk band the duck downpickers.\n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dfdesc = dfdesc.fillna(\"\")\n",
    "corpus = dfdesc.values[:,0]\n",
    "print(corpus[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837834, 1655398)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 837834/837834 [00:44<00:00, 19008.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "sparsevectors={}\n",
    "\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    sparsevectors[dfdesc.index[i]]=X[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('text_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(sparsevectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Stemmer\n",
    "#english_stemmer = Stemmer.Stemmer('en')\n",
    "#class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "#    def build_analyzer(self):\n",
    "#        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "#        return lambda doc: english_stemmer.stemWords(analyzer(doc))\n",
    "#    \n",
    "#vectorizer = StemmedTfidfVectorizer(min_df=1, stop_words='english', analyzer='word', ngram_range=(1,1))\n",
    "#vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The existing graph\n",
    "import networkx as nx\n",
    "G= nx.Graph()\n",
    "#add nodes\n",
    "nodes = pd.unique(df_edges_all[['id1', 'id2']].values.ravel())\n",
    "G.add_nodes_from(nodes)\n",
    "#add edges\n",
    "edges = [(row.id1,row.id2) for row in df_edges[df_edges[\"label\"]==1].itertuples()]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# keeping all the negative edges so we can compare results\n",
    "no_edges = [(row.id1,row.id2) for row in df_edges[df_edges[\"label\"]==0].itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Adding methods proposed in the https://link.springer.com/content/pdf/10.1038/s41598-019-57304-y.pdf\n",
    "def shortest_path(G:nx.Graph,source:int,target:int)->float:\n",
    "    try:\n",
    "        p=nx.shortest_path(G,source=source,target=target)\n",
    "        return len(p)-1\n",
    "    except nx.NetworkXNoPath:\n",
    "        return float(\"inf\")\n",
    "\n",
    "def distance(G:nx.Graph,source:int,target:int)->float:\n",
    "   '''\n",
    "   This method can be changed to any distance\n",
    "   '''\n",
    "   return shortest_path(G,source,target)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def distance_description(G,source:int,target:int)->float:\n",
    "    '''\n",
    "    This method can be changed to any distance\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    sp1=sparsevectors[source]\n",
    "    sp2=sparsevectors[target]\n",
    "    \n",
    "    return cosine_similarity(sp1,sp2)[0][0]\n",
    "\n",
    "\n",
    "def closeness_centrality(G:nx.Graph, source:int, target:int)->float:\n",
    "    dxy = nx.shortest_path(G,source=source,target=target)\n",
    "    return G.number_of_nodes()/shortest_path(G,source,target)\n",
    "\n",
    "def common_neighbors(G:nx.Graph, source:int, target:int)->list:\n",
    "    s_neighbors = list(G.adj[source].keys())\n",
    "    t_neighbors = list(G.adj[target].keys())\n",
    "    common_neighbors = set(s_neighbors).intersection(t_neighbors)\n",
    "    return common_neighbors\n",
    "\n",
    "def CCPA(G:nx.Graph, source:int, target:int,a:float = 0.5)->float:\n",
    "    '''\n",
    "    Common Neighbor and Centrality based Parameterized Algorithm\n",
    "    '''\n",
    "    return a*closeness_centrality(G,source,target)+(1-a)*len(common_neighbors(G,source,target))\n",
    "\n",
    "def CND(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Common Neighbor and Distance\n",
    "    '''\n",
    "    cn = common_neighbors(G,source,target)\n",
    "    if len(cn)>0:\n",
    "        return (len(cn)+1)/2\n",
    "    else:\n",
    "        if distance(G,source,target)==0:\n",
    "            return 0\n",
    "        return 1/distance(G,source,target)\n",
    "\n",
    "def PA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Preferential Attachment\n",
    "    '''\n",
    "    return G.degree[source]*G.degree[target]\n",
    "\n",
    "def AA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Adamic Adar\n",
    "    '''\n",
    "    similarity = 0.0\n",
    "    for neighbor in common_neighbors(G,source,target):\n",
    "        degree = G.degree[neighbor]\n",
    "        if degree > 1:\n",
    "            similarity += 1 / math.log(degree)\n",
    "    return similarity\n",
    "\n",
    "def CN(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Common Neighbor\n",
    "    '''\n",
    "    return len(common_neighbors(G,source,target))\n",
    "\n",
    "def SI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Sorensen Index\n",
    "    '''\n",
    "    if (G.degree[source]+G.degree[target]) ==0:\n",
    "        return 0\n",
    "    return 2*CN(G,source,target)/(G.degree[source]+G.degree[target])\n",
    "\n",
    "def JI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Jaccard Index\n",
    "    '''\n",
    "    s_neighbors = list(G.adj[source].keys())\n",
    "    t_neighbors = list(G.adj[target].keys())\n",
    "    common_neighbors = set(s_neighbors).intersection(t_neighbors)\n",
    "    all_neighbors = set(s_neighbors).union(t_neighbors)\n",
    "    if len(all_neighbors)==0:\n",
    "        return 0\n",
    "    return len(common_neighbors)/len(all_neighbors)\n",
    "\n",
    "def RA(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Resource Allocation\n",
    "    '''\n",
    "    similarity = 0.0\n",
    "    for neighbor in common_neighbors(G,source,target):\n",
    "        degree = G.degree[neighbor]\n",
    "        if degree > 1:\n",
    "            similarity += 1 / degree\n",
    "    return similarity\n",
    "\n",
    "def HPI(G:nx.Graph, source:int, target:int)->float:\n",
    "    '''\n",
    "    Hub Promoted Index\n",
    "    '''\n",
    "    if min([G.degree[source],G.degree[target]]) ==0 :\n",
    "        return 0\n",
    "    return CN(G,source,target)/min([G.degree[source],G.degree[target]])\n",
    "\n",
    "def create_metric_vector(tup):\n",
    "    G=tup[0]\n",
    "    source= tup[1]\n",
    "    target= tup[2]\n",
    "    functions = [CND, PA, AA, CN, SI, JI, RA, HPI,distance_description]\n",
    "    outputs = []\n",
    "    for func in functions:\n",
    "        output = func(G, source, target)\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CND, PA, AA, CN, SI, JI, RA, HPI]\n",
      "[1.0, 18, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.1132247541702719]\n",
      "[0.0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0, 0.021393415850264996]\n"
     ]
    }
   ],
   "source": [
    "# metrics names\n",
    "print(\"[CND, PA, AA, CN, SI, JI, RA, HPI]\")\n",
    "#This for connected nodes\n",
    "print(create_metric_vector((G,211858,312074)))\n",
    "#This is for unconnected nodes\n",
    "print(create_metric_vector((G,410411,460254)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CND, PA, AA, CN, SI, JI, RA, HPI]\n",
      "[0.0, 0, 0.0, 0, 0, 0, 0.0, 0, 0.23386042157952988]\n",
      "[0.0, 0, 0.0, 0, 0, 0, 0.0, 0, 0.015094458857096907]\n"
     ]
    }
   ],
   "source": [
    "# TEST SET\n",
    "# metrics names\n",
    "print(\"[CND, PA, AA, CN, SI, JI, RA, HPI]\")\n",
    "#This for connected nodes\n",
    "print(create_metric_vector((G,345657,467621)))\n",
    "#This is for unconnected nodes\n",
    "print(create_metric_vector((G,720678,447520)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def makedataset(df):\n",
    "    label=df.label\n",
    "    data=[]\n",
    "    allind=len(df.index)\n",
    "    counter=0\n",
    "    tups=[]\n",
    "    for i in tqdm(range(len(df.index))):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        tups.append((G,row.id1,row.id2))\n",
    "    with Pool(4) as p:\n",
    "        data=p.map(create_metric_vector, tups)\n",
    "    \n",
    "    datadf=pd.DataFrame(data)\n",
    "    return datadf,label\n",
    "\n",
    "def makedatasetapply(df):\n",
    "    label=df.label\n",
    "    datadf = df.progress_apply(lambda row: create_metric_vector((G,row['id1'],row['id2'])), axis=1,result_type='expand')\n",
    "    return datadf,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 189647/189647 [00:08<00:00, 21410.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "Xtest,Ytest=makedataset(df_edges_test)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "Xtest,Ytest=makedatasetapply(df_edges_test)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "#start = time.time()\n",
    "#X,Y=makedataset(df_edges)\n",
    "#end = time.time()\n",
    "#print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 189647/189647 [00:19<00:00, 9720.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.524142026901245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 758585/758585 [01:18<00:00, 9658.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.55381202697754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "Xtest,Ytest=makedatasetapply(df_edges_test)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()\n",
    "X,Y=makedatasetapply(df_edges)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007842600825296947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "model = XGBClassifier()\n",
    "\n",
    "#X_train, X_test, y_trainn, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "model.fit(X, Y)\n",
    "preds = model.predict(Xtest)\n",
    "f1=f1_score(Ytest, preds)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::bkcharts==0.2=py39h06a4308_0\n",
      "  - pytorch/linux-64::torchaudio==0.11.0=py39_cu113\n",
      "  - defaults/noarch::seaborn==0.11.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::altair==4.1.0=py_1\n",
      "  - defaults/noarch::dask==2021.10.0=pyhd3eb1b0_0\n",
      "  - pytorch/noarch::captum==0.5.0=0\n",
      "  - pytorch/linux-64::torchvision==0.12.0=py39_cu113\n",
      "  - defaults/linux-64::anaconda==custom=py39_1\n",
      "  - defaults/linux-64::_anaconda_depends==2021.11=py39_0\n",
      "  - defaults/linux-64::statsmodels==0.13.2=py39h7f8727e_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: | ^C\n",
      "failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
